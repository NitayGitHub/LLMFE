"""
[PREFIX]

###
<Task>
Which direction does the balance scale tip to? Right, left, or balanced?

###
<Features>
[FEATURES]

###
<Examples>
[EXAMPLES]
[SUFFIX]
"""

@evaluate.run
def evaluate(data: dict):
    """ Evaluate the feature transformations on data observations."""

    from sklearn import preprocessing
    from sklearn.model_selection import StratifiedKFold, KFold
    from sklearn.metrics import accuracy_score
    from preprocessing import preprocess_datasets
    import xgboost as xgb
    import torch
    import numpy as np

    # Load data observations
    label_encoder = preprocessing.LabelEncoder()
    inputs, outputs, is_cat, is_regression = data['inputs'], data['outputs'], data['is_cat'], data['is_regression']
    X = modify_features(inputs)
    y = label_encoder.fit_transform(outputs)

    # Encode categorical string columns
    for col in X.columns:
        if X[col].dtype == 'string':
            X[col] = label_encoder.fit_transform(X[col])

    # Choose cross-validation strategy
    kf = KFold(n_splits=4, shuffle=True, random_state=42) if is_regression else StratifiedKFold(n_splits=4, shuffle=True, random_state=42)

    scores = []

    # 4-Fold Cross-Validation
    for train_idx, test_idx in kf.split(X, y):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        X_train_new, X_test_new = preprocess_datasets(X_train, X_test, None)
        
        # Convert to tensors
        X_train = torch.tensor(X_train_new.to_numpy())
        X_test = torch.tensor(X_test_new.to_numpy())

        # Load model
        model = xgb.XGBClassifier(random_state=42)

        model.fit(X_train_new, y_train)
        
        y_pred = model.predict(X_test_new)
        score = accuracy_score(y_test, y_pred)
        scores.append(score)

    # Calculate average score
    avg_score = np.mean(scores)

    return avg_score, inputs, outputs

@equation.evolve
def modify_features(df_input) -> pd.DataFrame:
    """
    Thought 1: The absolute difference between Left-Weight and Right-Weight can capture the imbalance in weight distribution.
    New Feature 1: weight_difference | weight_difference = abs(Left-Weight - Right-Weight)
    """
    df_output = df_input.copy()
    
    # Calculate absolute difference between Left-Weight and Right-Weight
    df_output['weight_difference'] = abs(df_output['Left-Weight'] - df_output['Right-Weight'])
    
    return df_output